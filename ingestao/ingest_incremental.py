from datetime import datetime, timedelta
from psycopg2.extras import execute_batch

from common import get_session, obter_token, get_db_conn, BASE_URL

# ======================================================
# CONFIGURA√á√ïES
# ======================================================
FOLGA_MINUTOS = 5
SENSOR_BATCH_SIZE = 50

# ======================================================
# PIPELINE INCREMENTAL
# ======================================================
def run_incremental():
    session = get_session()
    token = obter_token(session)
    headers = {"Authorization": f"Bearer {token}"}

    conn = get_db_conn()
    cur = conn.cursor()

    # üîë ESTADO: √∫ltimo timestamp por sensor
    cur.execute("""
        SELECT
            sensor_id,
            COALESCE(MAX(data_leitura), NOW() - INTERVAL '1 day') AS last_ts
        FROM leituras
        GROUP BY sensor_id
    """)
    sensores = cur.fetchall()

    if not sensores:
        print("‚ö† Nenhum sensor encontrado na base.")
        return

    print(f"üîé {len(sensores)} sensores para ingest√£o incremental")

    # üîÑ PROCESSA EM LOTES
    for i in range(0, len(sensores), SENSOR_BATCH_SIZE):
        lote = sensores[i:i + SENSOR_BATCH_SIZE]

        # menor timestamp do lote (com folga)
        start_dt = min(s[1] for s in lote) - timedelta(minutes=FOLGA_MINUTOS)

        # ‚ö† API N√ÉO ACEITA TIMEZONE
        start_str = start_dt.strftime("%Y-%m-%dT%H:%M:%S")
        end_str = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%S")

        sensor_ids = ",".join(str(s[0]) for s in lote)

        print(f"‚û° Buscando dados de {start_str} at√© {end_str} | Sensores: {len(lote)}")

        r = session.get(
            f"{BASE_URL}/SensorData",
            headers=headers,
            params={
                "version": "1.3",
                "startDate": start_str,
                "endDate": end_str,
                "sensorIds": sensor_ids
            }
        )

        # DEBUG √öTIL EM CASO DE ERRO
        if r.status_code != 200:
            print("‚ùå Erro na API SensorData")
            print("Status:", r.status_code)
            print("Resposta:", r.text)
            r.raise_for_status()

        dados = r.json()
        if not dados:
            print("   ‚Ü™ Nenhum dado novo")
            continue

        registros = [
            (d["sensorId"], d["readingDate"], d["sensorValue"])
            for d in dados
        ]

        execute_batch(cur, """
            INSERT INTO leituras (
                sensor_id,
                data_leitura,
                valor_sensor
            )
            VALUES (%s,%s,%s)
            ON CONFLICT (sensor_id, data_leitura) DO NOTHING
        """, registros, page_size=1000)

        conn.commit()
        print(f"   ‚úî {len(registros)} registros inseridos")

    cur.close()
    conn.close()
    print("\n‚ö° Ingest√£o incremental conclu√≠da com sucesso")

# ======================================================
# MAIN
# ======================================================
if __name__ == "__main__":
    run_incremental()
